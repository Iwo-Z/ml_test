---
title: "ml_test - Wine Quality"
author: "Iwo"
format: 
  html:
    self-contained: true
    toc: true
    toc-depth: 4
    toc-location: right
    toc-title: "Spis treści"
    number-sections: true
    number-depth: 4
    number-offset: 0
    code-fold: show
    code-summary: "Show the code"
    code-tools: true
    code-block-bg: true
    code-block-border-left: "black"
    code-line-numbers: false
    code-copy: true
    html-math-method: katex
    smooth-scroll: true
    anchor-sections: true
    link-external-icon: true
    link-external-newwindow: true
    theme:
        light: cosmo
        dark: darkly
    fontsize: 1.0em
    linestretch: 1.5
execute:
  warning: false
  echo: true
  error: false
editor_options: 
  chunk_output_type: console
---

# Ładowanie bibliotek

```{r}
library("tidymodels")
library("AmesHousing")
library("skimr")
library("GGally")
library("vip")
library("patchwork")
library("tibble")
tidymodels_prefer()

set.seed(222)
```

# Wczytanie i opis danych

Dane Wine Quality (UCI) dostępne są jako dwa pliki: `winequality-red.csv` i `winequality-white.csv`

Każdy rekord odpowiada jednemu winu i opisany jest zestawem cech numerycznych.

| Nazwa zmiennej | Opis | Jednostka / Zakres | Typ danych |
|----------------|------|--------------------|-------------|
| **fixed acidity** | Zawartość kwasów stałych (głównie kwas winowy) | g/dm³ | numeryczna |
| **volatile acidity** | Kwasowość lotna (głównie kwas octowy); zbyt wysoka powoduje nieprzyjemny zapach | g/dm³ | numeryczna |
| **citric acid** | Zawartość kwasu cytrynowego – wpływa na świeżość i smak | g/dm³ | numeryczna |
| **residual sugar** | Cukier resztkowy po fermentacji | g/dm³ | numeryczna |
| **chlorides** | Ilość chlorków (zawartość soli) | g/dm³ | numeryczna |
| **free sulfur dioxide** | Wolny dwutlenek siarki – środek konserwujący | mg/dm³ | numeryczna |
| **total sulfur dioxide** | Całkowity dwutlenek siarki (wolny + związany) | mg/dm³ | numeryczna |
| **density** | Gęstość wina – zależy od zawartości cukru i alkoholu | g/cm³ | numeryczna |
| **pH** | Odczyn kwasowości – niższe wartości oznaczają bardziej kwaśne wino | 0–14 | numeryczna |
| **sulphates** | Zawartość siarczanów – wpływa na stabilność i smak | g/dm³ | numeryczna |
| **alcohol** | Zawartość alkoholu etylowego | % obj. | numeryczna |
| **quality** | Ocena jakości wina przez ekspertów | skala 0–10 (zazwyczaj 3–8) | numeryczna / kategoryczna |
| **type** | Typ wina – czerwone lub białe | `red` / `white` | kategoryczna |

---

Dane te pozwalają analizować, które cechy chemiczne najbardziej wpływają na ocenę jakości wina (`quality`).


```{r}
library(readr)

# download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv", destfile = "winequality-red.csv")
# download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv", destfile = "winequality-white.csv")

# separator = ";"
red  <- read_delim("winequality-red.csv", delim = ";", show_col_types = FALSE)
white <- read_delim("winequality-white.csv", delim = ";", show_col_types = FALSE)

red  <- red |> mutate(type = "red")
white <- white |> mutate(type = "white")

wine_raw <- red

dim(wine_raw)
skimr::skim(wine_raw)
```

# Cel

Celem analizy jest zrozumienie, które cechy chemiczne wpływają na ocenę jakości wina. Zmienna celu to `quality` — ocena sensoryczna w skali całkowitej. Możemy traktować ją jako regresję (ciągła przybliżona) lub jako problem klasyfikacji/porządkowy.

```{r}
wine_raw |> select(quality) |> skimr::skim()

# rozkład jakości
library(ggplot2)
ggplot(wine_raw, aes(quality)) + geom_bar() + ggtitle("Rozkład jakości (quality)")
```

# Wstępna eksploracja

Szybkie wykresy i korelacje z `quality`.

```{r}
num_vars <- wine_raw |> select(where(is.numeric)) |> names()
sel <- c(num_vars[1:8], "quality")

GGally::ggpairs(wine_raw |> select(all_of(sel)) |> na.omit(), lower = list(continuous = "smooth"))
```

```{r}
cors <- wine_raw |> select(where(is.numeric)) |> cor(use = "pairwise.complete.obs")
q_cor <- data.frame(
  feature = rownames(cors),
  correlation = cors[, "quality"]
)
q_cor |> arrange(desc(abs(correlation))) |> slice(1:10)
```

- **`alcohol`** ma **najsilniejszą dodatnią korelację** z jakością wina – im wyższa zawartość alkoholu, tym wino jest zwykle lepiej oceniane.  
- **`volatile acidity`** wykazuje **umiarkowaną ujemną korelację** – większa kwasowość lotna (np. kwas octowy) obniża ocenę wina.
- **`pH`** jest praktycznie niepowiązane z oceną jakości.  

```{r}
p1 <- ggplot(wine_raw, aes(alcohol)) + geom_histogram(bins=30) + ggtitle("Alcohol")
p2 <- ggplot(wine_raw, aes(.data[['volatile acidity']])) + geom_histogram(bins=30) + ggtitle("volatile acidity")
p3 <- ggplot(wine_raw, aes(pH)) + geom_histogram(bins=30) + ggtitle("pH")

p1 + p2 + p3
```

# Podział na zbiór treningowy i testowy

Dane zostały podzielone w proporcji **80% / 20%** na zbiór treningowy i testowy z użyciem stratyfikacji względem zmiennej `quality`. Dzięki temu rozkład jakości pozostaje podobny w obu zbiorach, co zwiększa wiarygodność oceny modelu.


```{r}
split <- initial_split(wine_raw, prop = 0.8, strata = quality)
train_tbl <- training(split)
test_tbl  <- testing(split)

nrow(train_tbl)
nrow(test_tbl)
```

# Receptura

Plan receptury:

- usunięcie braków

- usunięcie cech z niemal zerową wariancją

- normalizacja wszystkich predyktorów numerycznych

```{r recipe}
library(recipes)

wine_recipe <- recipe(quality ~ ., data = train_tbl) |>
  # jeśli łączysz oba zbiory, type jest nominalne — w przeciwnym razie ten krok nic nie robi
  step_impute_median(all_numeric_predictors()) |>
  step_nzv(all_predictors()) |>
  step_normalize(all_numeric_predictors())

summary(wine_recipe)
```

# Specyfikacje modeli

W tej części definiujemy cztery różne podejścia do regresji jakości wina.
Każdy model wykorzystuje inne założenia i metody regularyzacji lub uogólnienia.

- Regresja liniowa (OLS) – prosta baza porównawcza.

- GLMNet – regresja liniowa z regularyzacją L1/L2 (ridge / lasso).

- Random Forest (ranger) – model drzew losowych, dobrze radzi sobie z nieliniowościami.

- XGBoost – wydajny model boostingowy, bardzo skuteczny.

```{r models-setup}
# 1. Linear regression (OLS)
lm_spec <- linear_reg() |>
  set_engine("lm", importance = "impurity") |>
  set_mode("regression")

# 2. Regularized (glmnet)
glmnet_spec <- linear_reg(penalty = tune(), mixture = tune()) |>
  set_engine("glmnet", importance = "impurity")

# 3. Random forest (ranger)
rf_spec <- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) |>
  set_engine("ranger", importance = "impurity") |>
  set_mode("regression")

# 4. Gradient boosting (xgboost)
xgb_spec <- boost_tree(trees = tune(), tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), sample_size = tune()) |>
  set_engine("xgboost") |>
  set_mode("regression")
```

# Workflow

Workflow on wcześniej zdefiniowaną recepturę (`wine_recipe`) z wybranym modelem uczenia maszynowego, dzięki czemu cały proces przygotowania danych i trenowania odbywa się w jednej strukturze.

```{r}
library(workflows)

wf_lm <- workflow() |> add_recipe(wine_recipe) |> add_model(lm_spec)
wf_glmnet <- workflow() |> add_recipe(wine_recipe) |> add_model(glmnet_spec)
wf_rf <- workflow() |> add_recipe(wine_recipe) |> add_model(rf_spec)
wf_xgb <- workflow() |> add_recipe(wine_recipe) |> add_model(xgb_spec)
```

# Walidacja krzyżowa i plan strojenia

Tworzony jest plan walidacji krzyżowej (5-fold CV), który pozwala ocenić modele na różnych podzbiorach danych.

Dodatkowo określane są zakresy hiperparametrów i siatki (grid) dla każdego modelu, które zostaną użyte w procesie strojenia.

```{r}
library(dials)
library(rsample)

cv_splits <- vfold_cv(train_tbl, v = 5, strata = quality)

glmnet_params <- parameters(penalty(), mixture())
rf_params <- parameters(
  mtry(range = c(1, floor(sqrt(ncol(train_tbl)-1)))), 
  min_n()
)

xgb_params <- parameters(
  tree_depth(), 
  trees(), 
  learn_rate(), 
  loss_reduction(), 
  sample_size = sample_prop(range = c(0.5, 1.0))
)

xgb_params_final <- finalize(xgb_params, train_tbl)

# Create grids
glmnet_grid <- grid_regular(glmnet_params, levels = 5)
rf_grid <- grid_random(rf_params, size = 20)
xgb_grid <- grid_random(xgb_params_final, size = 20)
```

# Strojenie modeli (tuning)

Tutaj każdy model jest strojeny (tuningowany) przy użyciu wcześniej zdefiniowanej walidacji i siatek parametrów.
Wyniki oceniamy na podstawie trzech metryk: RMSE, R² i MAE.

```{r}
library(tune)
library(glmnet)
library(xgboost)
library(ranger)

reg_metrics <- metric_set(rmse, rsq, mae)

# GLMnet
glmnet_res <- tune_grid(
  wf_glmnet, 
  resamples = cv_splits, 
  grid = glmnet_grid, 
  metrics = reg_metrics,
  control = control_grid(save_pred = FALSE, verbose = TRUE)
)

collect_metrics(glmnet_res)

# Random Forest
rf_res <- tune_grid(
  wf_rf, 
  resamples = cv_splits, 
  grid = rf_grid, 
  metrics = reg_metrics,
  control = control_grid(verbose = TRUE)
)
collect_metrics(rf_res)

# XGBoost
xgb_res <- tune_grid(
  wf_xgb, 
  resamples = cv_splits, 
  grid = xgb_grid, 
  metrics = reg_metrics,
  control = control_grid(verbose = TRUE)
)
collect_metrics(xgb_res)
```



